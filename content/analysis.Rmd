---
title: Analysis 1
description:
toc: true
featuredVideo: 
featuredImage: https://www.suno.edu/assets/suno/images/Admissions/international-students.jpeg
draft: false
---

## Motivation
Most of our teammates are international students from China and Korea. We found an article that the number of international students in the US unprecedentedly decreased during 2019 to 2020. The widespread travel restrictions tend to lead to a sharp decline in enrollments of new students outside of the US. We wanted to check what would affect the international students to choose certain institutions in the US. 
One of our teammates, Yawei suggested that the top three considerations were: safety, ranking of the university in my field, and the “dynamics” of the campus. The percentage of the international student body would fall under the third category. However, while there has been quite convenient data on the first two categories, the judgment of the third was more based on gut or anecdotes. The rankings on US News, for example, are a weighted composite score of many aspects, but we were not sure whether the international student body is one of the criteria (probably not, but I believe there is correlation there). Therefore, we considered that we could explore more about this potential correlation (x=% of international students, y=rankings) while trying to add in other interesting and relevant information, such as the nationalities of international students, crime rate of the city, etc

The “main” research question is to explore the relationship between percentage of international student population (x-axis) and the ranking of US universities (y-axis). We can then add more interesting complexities/layers to the basic graph through “group_by”, “color”, “fill”, “facet” and different “geoms_plots” using variables such as nationalities, number of (top xx) universities in the city, crime rates of the city, location of the university (on a US map), and ranking type (e.g., undergraduate, graduate cs, graduate education, graduate business, graduate law). 
We also wanted to answer the questions below: 
How has the number of international students in the US changed over time?  (x= school years, y= international students’ population)
New enrollment percentage of international students (x= school years, y= international students’ population % change)
How do new enrollment trends vary by academic level? 
Breakdown of international students by the US region they live (2021 vs 2016)

## Breadth and Depth of DA
Our group’s target variables are the international student population (ISPo) and proportion (ISPr) in US colleges, and we aim to identify the potential factors that correlate to and predict ISPo and ISPr. 

## Early Data Analysis
In our earlier data analysis (Blog Post 4), we examined the relationship between the dependent variable ISPr and the independent variable, an additive indicator reflecting the number of “Alumni of an institution winning Nobel Prizes and Fields Medals” and “Papers indexed in Science Citation Index-Expanded and Social Science Citation Index”. We did this by making predictions with 7 regression models (logistic, quasipolynomial, Gaussian, Poisson, Inverse Gaussian, Gamma) after shuffling and splitting the data with a 70-30 ratio for the train and test sets. By evaluating the AIC and fisher score, we selected the inverse gaussian glm as the best fit of all 7 models. Below we display our linear regression, logistic regression, and inverse gaussian regression. 
 
The main limitation is that we naively selected one predictor variable (Alumni and Publications) and did not assess the correlations.

## Current Data Analysis
In our following analysis, we address the limitation of the previous analysis through feature extraction. Since we are solving a regression problem, our output is a continuous variable. After more data cleaning, we have a total of 35 independent variables concerning every observed college. They are split into 22 continuous variables and 15 categorical variables. To explore continuous variables’ pairwise correlations with the target variables, we have used a correlation matrix. 

```{r, echo=FALSE, message = FALSE}
 suppressWarnings({
 library(tidyverse)
 library(caTools)
 library(ggplot2)
 library(ggcorrplot)
 library(reshape2)
 })

 get_upper_tri <- function(cormat){
   cormat[lower.tri(cormat)]<- NA
   return(cormat)
 }

 reorder_cormat <- function(cormat){
   dd <- as.dist((1-cormat)/2)
   hc <- hclust(dd)
   cormat <-cormat[hc$order, hc$order]
 }

 suppressWarnings({
 clean_data <- read.csv(here::here("dataset/clean_data.csv"))
 num_data <- clean_data[,unlist(lapply(clean_data, is.numeric))]
 cormat <- round(cor(num_data, use = "complete.obs"), 2)
 cormat <- reorder_cormat(cormat)
 })


 suppressWarnings({
 upper_tri <- get_upper_tri(cormat)
 melted_cormat <- melt(upper_tri, na.rm = TRUE)
 ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
   geom_tile(color = "white")+
   scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                        midpoint = 0, limit = c(-1,1), space = "Lab", 
                        name="Pearson\nCorrelation") +
   theme_minimal()+ # minimal theme
   theme(axis.text.x = element_text(angle = 45, vjust = 1,size = 6, hjust = 1)) + coord_fixed()
 })

 suppressWarnings({
 ind_num <- melted_cormat[(melted_cormat$Var1 == "international_students_max" & melted_cormat$Var2 != "international_students_max" & abs(melted_cormat$value) >=0.4 ), ]$Var2
 ind_prop <- melted_cormat[(melted_cormat$Var1 == "international_students_natlib" & melted_cormat$Var2 != "international_students_natlib" & abs(melted_cormat$value) >=0.4 ), ]$Var2
 ggheatmap
 })
```

The correlation matrix helps find high positive or negative correlations, and we select numerical features that have an absolute value of correlation coefficient greater than 0.4 with respect to ISPo and ISPr. 
For ISPo, the relevant numerical features are international_students_opendoors, enrollment_top120enrollment, city_population, international_students_qs, international_students_natlib, and city_population_density.
For ISPr, the relevant numerical features are city_population_density and faculty_count_qs. 

## Feature Extraction (In Progress)
We have found that computing the correlation between categorical and continuous variables is a bit tedious; since the categorical variables are not binary, we cannot apply point-biserial correlation. We have identified a few potential methods to work around such as numerical encoding from categorical to numerical, logistic regression, and the x2y metric. We are currently using logistic regression to compare the pairwise correlations. We understand this approach assumes a linear relationship between the predictor and the logit of the outcome.

The 15 categorical variables are "university", "city", "state", "selectivity", "world_rank_cat_arwu", "world_rank_qs", "national_rank_arwu", "type1_all", "type2_carnegie", "type3_natlib", "type4_carnegie", "enrprofile2021_carnegie", "locale_carnegie", "size_qs", and "research_output_qs".

We remove the university variable because it is unique for all observations. Similarly, because we have limited data in general for cities and states, they are not reliable predictors and introduce unnecessary noise. Thus, we are in the process of numerically encoding the variables: selectivity, size_qs, research_output_qs, type1_all, type2_carnegie, and locale_carnegie. 

*Tentatively*, we will use the following numerical features out of 35 dependent variables: 
enrollment_top120enrollment,  
city_population,  
City_population_density

The following modeling section exclusively addresses our current data analysis.

## Modeling

Linear Regression has a mean absolute error of *0.02577159*
and Logistic Regression has a mean absolute error of  *0.02558677*

```{r echo = FALSE, warning = FALSE}
suppressWarnings({
  clean_data <- read.csv(here::here("dataset/clean_data.csv"))

processed_data <- na.omit(data.frame(y = clean_data$international_students_natlib,
                   x1 = clean_data$faculty_count_qs,
                   x2= clean_data$city_population,
                   x3= clean_data$city_population_density
                   ) )

split <- sample.split(processed_data, SplitRatio = 0.7)
dt = sort(sample(nrow(processed_data), nrow(processed_data)*.7))
train<-processed_data[dt,]
test<-processed_data[-dt,]
})

suppressWarnings({
linear_model <- lm(y~x1+x2+x3, data=train)
summary(linear_model)


ggplot(test,aes(x1+x2+x3, y)) +
  geom_point() +
  geom_smooth(method = 'loess', formula = 'y ~ x', se=TRUE, color='turquoise4') +
  theme_minimal() +
  labs(x='Faculty count, city population and density factor (additive)', y='International Student Proportions', title='Linear Regression Plot') +
  theme(plot.title = element_text(hjust=0.5, size=20, face='bold')) 

})

suppressWarnings({
logistic_model <- glm(y~x1+x2+x3, data=train, family = binomial()) #Logistic 1
summary(logistic_model)

y_predict_logit <- data.frame(x1 = test$x1,x2 = test$x2, x3 = test$x3, y =predict(logistic_model, test, type = "response"))

logit_result<- ggplot(test, aes(x1+x2+x3, y)) + geom_point() + geom_smooth(data = y_predict_logit, method = 'loess', formula = 'y ~ x', se=FALSE, color='red4', alpha = 0.1)+
  theme_minimal() +
  labs(x='Faculty count, city population and density factor (additive)', y='International Student Proportions', title='Logistic Regression') +
  theme(plot.title = element_text(hjust=0.5, size=20, face='bold')) 
logit_result
})
```

## Conclusion
Our current analysis suggests that the overall enrollment of students, city population, and city population density are indicators for predicting ISPo and ISPr.

# Flaws and limitations
### Limitation 1. 
One of the main limitations is that for our models we don’t introduce any categorical variables. We address this in the Feature Extraction (In Progress) section.
Alternatively, we are interested in leveraging the regsubsets subroutine in the leaps library to compare modeling with different variables, which provides performance criteria such as Adjusted R2 score, Bayesian Information Criterion, Mallow’s Cp. 
 
### Limitation 2. 
On the other hand, due to the sparsity of the data, if we include certain predictors, the overall data for training and testing may shrink to 10 observations, which leads to not unreliable modeling and predictions. 

-------


## Rubric: On this page

you will


* Introduce what motivates your Data Analysis (DA)
  * Which variables and relationships are you most interested in?
  * What questions are you interested in answering?
* Breadth of the DA
  * Make sure that you ask enough initial questions to explore the different variables in your data.
  * i.e. Do you explore more than just one or two variables? Do you explore a few different relationships or many?
* Depth of the DA
  * When you answer one question, usually more questions arise as well. 
  * The depth of the DA is about coming up with and exploring the answers to these questions, often iterating the process a few times.
* Modeling and Inference 
  * You should also include some kind of formal statistical model and/or inference. This could be a linear regression, logistic regression, hypothesis testing etc.
  * Explain the techniques you used for validating your results.
  * Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
* Explain the flaws and limitations of your analysis
  * Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions? ...
* Clarity Figures
  * Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
  * Each figure should provide a key insight. Too many figures or other data summaries can detract from this.
* Clarity of Explanations
  * Do you introduce why you are doing each analysis?
  * How well do you explain each figure/result?
  * Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
* Organization and cleanliness.
  * Make sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.

  
**NOTE**: Your Data Analysis can be broken up into multiple pages if that helps with your organization.